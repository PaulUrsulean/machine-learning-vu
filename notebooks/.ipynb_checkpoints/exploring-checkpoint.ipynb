{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"../toxic_comment_data/train.csv\")\n",
    "comments2 = pd.read_csv(\"../toxic_comment_data/test_with_solutions.csv\")\n",
    "comments2 = comments2.drop(columns=[\"Usage\"])\n",
    "comments = pd.concat([comments,comments2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Here we examine the training data (labeled with whether something is an insult or not). Some charming people.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 6594\n",
      "Columns: 3\n",
      "Number of insulting comments: 1742\n",
      "Number of non-insulting comments: 4852\n",
      "Number of comments missing dates: 1242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620171226Z</td>\n",
       "      <td>\"@SDL OK, but I would hope they'd sign him to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>20120503012628Z</td>\n",
       "      <td>\"Yeah and where are you now?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"shut the fuck up. you and the rest of your fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>20120502173553Z</td>\n",
       "      <td>\"Either you are fake or extremely stupid...may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20120620160512Z</td>\n",
       "      <td>\"That you are an idiot who understands neither...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...\n",
       "5       0  20120620171226Z  \"@SDL OK, but I would hope they'd sign him to ...\n",
       "6       0  20120503012628Z                      \"Yeah and where are you now?\"\n",
       "7       1              NaN  \"shut the fuck up. you and the rest of your fa...\n",
       "8       1  20120502173553Z  \"Either you are fake or extremely stupid...may...\n",
       "9       1  20120620160512Z  \"That you are an idiot who understands neither..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Rows: \" + str(comments.shape[0]))\n",
    "print(\"Columns: \" + str(comments.shape[1]))\n",
    "print(\"Number of insulting comments: \" + str(len(comments[comments['Insult'] == 1])))\n",
    "print(\"Number of non-insulting comments: \" + str(len(comments[comments['Insult'] == 0])))\n",
    "print(\"Number of comments missing dates: \" + str(comments.isnull().sum().Date))\n",
    "\n",
    "comments[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The comments are all unicode escaped, so inplace of special symbols there is some \\escapeCode. It can be decoded if necessary as shown below.**\n",
    "\n",
    "**Most of the data is english, but not all of it, not really a big deal though I suppose.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1eddng bi\\u1ec3u t\\xecnh 2011 c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ? \\nC\\xe1c ng\\u01b0 d\\xe2n ng\\u1ed3i cu\\xed \\u0111\\u1ea7u chi\\u1ee5 nh\\u1ee5c c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ?\\nC\\xe1c n\\xf4ng d\\xe2n gi\\u1eef \\u0111\\u1ea5t \\u1edf V\\u0103n Giang, C\\u1ea7n Th\\u01a1 c\\xf3 \\xf4n ho\\xe0 kh\\xf4ng ?\\n.................\\nR\\u1ed1t cu\\u1ed9c \\u0111\\u01b0\\u1ee3c g\\xec\\xa0 th\\xec ch\\xfang ta \\u0111\\xe3 bi\\u1ebft !\\nAi c\\u0169ng y\\xeau chu\\u1ed9ng ho\\xe0 b\\xecnh, nh\\u01b0ng \\u0111\\xf4i khi ho\\xe0 b\\xecnh ch\\u1ec9 th\\u1eadt s\\u1ef1 \\u0111\\u1ebfn sau chi\\u1ebfn tranh m\\xe0 th\\xf4i.\\nKh\\xf4ng c\\xf2n con \\u0111\\u01b0\\u1eddng n\\xe0o ch\\u1ecdn kh\\xe1c \\u0111\\xe2u, \\u0111\\u1eebng m\\u01a1 th\\xeam n\\u01b0\\xe3.\"\n"
     ]
    }
   ],
   "source": [
    "sample_comment = comments.iloc[4].Comment\n",
    "print(sample_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Các bạn xuống đường biểu tình 2011 có ôn hoà không ? \n",
      "Các ngư dân ngồi cuí đầu chiụ nhục có ôn hoà không ?\n",
      "Các nông dân giữ đất ở Văn Giang, Cần Thơ có ôn hoà không ?\n",
      ".................\n",
      "Rốt cuộc được gì  thì chúng ta đã biết !\n",
      "Ai cũng yêu chuộng hoà bình, nhưng đôi khi hoà bình chỉ thật sự đến sau chiến tranh mà thôi.\n",
      "Không còn con đường nào chọn khác đâu, đừng mơ thêm nưã.\"\n"
     ]
    }
   ],
   "source": [
    "decoded_comment = bytes(sample_comment, 'ascii').decode('unicode-escape')\n",
    "print(decoded_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Lets add a column to the dataset that contains the length of every comment, we can use the built in method .str.len() from pandas, as opposed to doing something like len(x) where x is the comment string. This will deal with NaN cases automatically, were a string to not to be present for whatever reason. This also prevents a potential TypeError with standard len. **\n",
    "\n",
    "_Note: this length measurement obviously includes all the unicode escape characters, so I also created a new column \"True Length\" which represents the length you would expect if it was printed normally. This utilizes the function below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def true_length(input):\n",
    "    if type(input) is str:\n",
    "        return len(bytes(input, 'ascii').decode('unicode-escape'))\n",
    "    else: \n",
    "        return -1 #arbitrary, should not ever happen with this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Raw_Length</th>\n",
       "      <th>True_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>20120619203151Z</td>\n",
       "      <td>\"Your anti-Semitic rants are not welcomed here...</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620175146Z</td>\n",
       "      <td>\"@Nonstopdrivel Was FredEx on this team?\"</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>20120619033424Z</td>\n",
       "      <td>\"god, you're tiresome. get a life, you loser.\"</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>20120612141919Z</td>\n",
       "      <td>\"stop pretending ur not bradley's side. you're...</td>\n",
       "      <td>244</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Insult             Date  \\\n",
       "59       1  20120619203151Z   \n",
       "60       0  20120620175146Z   \n",
       "61       1  20120619033424Z   \n",
       "62       0  20120612141919Z   \n",
       "\n",
       "                                              Comment  Raw_Length  True_Length  \n",
       "59  \"Your anti-Semitic rants are not welcomed here...          77           76  \n",
       "60          \"@Nonstopdrivel Was FredEx on this team?\"          41           41  \n",
       "61     \"god, you're tiresome. get a life, you loser.\"          46           46  \n",
       "62  \"stop pretending ur not bradley's side. you're...         244          229  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['Raw_Length']  = comments['Comment'].str.len()\n",
    "comments['True_Length'] = comments['Comment'].apply(lambda x: true_length(x))\n",
    "\n",
    "comments[59:63]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Just wanted to try normalizing the length...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Raw_Length</th>\n",
       "      <th>True_Length</th>\n",
       "      <th>Norm_True_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "      <td>92</td>\n",
       "      <td>89</td>\n",
       "      <td>0.004691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "      <td>390</td>\n",
       "      <td>384</td>\n",
       "      <td>0.021366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "      <td>271</td>\n",
       "      <td>271</td>\n",
       "      <td>0.014979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "      <td>728</td>\n",
       "      <td>377</td>\n",
       "      <td>0.020970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620171226Z</td>\n",
       "      <td>\"@SDL OK, but I would hope they'd sign him to ...</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>0.013509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>20120503012628Z</td>\n",
       "      <td>\"Yeah and where are you now?\"</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"shut the fuck up. you and the rest of your fa...</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>0.004691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>20120502173553Z</td>\n",
       "      <td>\"Either you are fake or extremely stupid...may...</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>0.002883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20120620160512Z</td>\n",
       "      <td>\"That you are an idiot who understands neither...</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0.003957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment  \\\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"   \n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...   \n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...   \n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...   \n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...   \n",
       "5       0  20120620171226Z  \"@SDL OK, but I would hope they'd sign him to ...   \n",
       "6       0  20120503012628Z                      \"Yeah and where are you now?\"   \n",
       "7       1              NaN  \"shut the fuck up. you and the rest of your fa...   \n",
       "8       1  20120502173553Z  \"Either you are fake or extremely stupid...may...   \n",
       "9       1  20120620160512Z  \"That you are an idiot who understands neither...   \n",
       "\n",
       "   Raw_Length  True_Length  Norm_True_Length  \n",
       "0          20           20          0.000791  \n",
       "1          92           89          0.004691  \n",
       "2         390          384          0.021366  \n",
       "3         271          271          0.014979  \n",
       "4         728          377          0.020970  \n",
       "5         245          245          0.013509  \n",
       "6          29           29          0.001300  \n",
       "7          89           89          0.004691  \n",
       "8          57           57          0.002883  \n",
       "9          76           76          0.003957  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_max = comments['True_Length'].max()\n",
    "col_min = comments['True_Length'].min()\n",
    "comments['Norm_True_Length'] = comments['True_Length'].apply(lambda x: (x-col_min)/(col_max-col_min))\n",
    "comments[75:78]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Sanity check to verify that the min value has norm length 0, and max value has norm length 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "maxv = comments.iloc[comments['True_Length'].idxmax()].Norm_True_Length\n",
    "minv = comments.iloc[comments['True_Length'].idxmin()].Norm_True_Length\n",
    "print(\"Minimum length:\",comments['True_Length'].min(),\"      normalized:\",minv)\n",
    "print(\"Maximum length:\",comments['True_Length'].max(),\"  normalized:\",maxv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(comments.True_Length,color=\"purple\",bins=100)\n",
    "plt.xlabel('Length of comment in characters')\n",
    "plt.ylabel('Number of occurences')\n",
    "plt.title('Comment length distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Clearly, a vast majority of the comments are less than 2500 characters in length..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.boxplot(comments[comments['True_Length'] < 5000].True_Length,1,'',0)\n",
    "plt.title(\"Boxplot of comment length (outliers removed)\")\n",
    "plt.ylabel(\"Comment\")\n",
    "plt.xlabel(\"Length\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Longest comment:  \" + str(comments['True_Length'].max()) + \" characters\")\n",
    "print(\"Shortest comment: \" + str(comments['True_Length'].min()) + \" characters\")\n",
    "print(\"Average:          \" + str(round(comments.True_Length.mean())) + \" characters\")\n",
    "print(\"Median:          \" + str(round(comments.True_Length.median())) + \" characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ins = len(comments[comments['Insult'] == 1]) # number of insulting commments\n",
    "non = len(comments[comments['Insult'] == 0]) # number of non-insulting comments\n",
    "percents = [ins,non]\n",
    "\n",
    "labels = 'Insulting', 'Non-Insulting'\n",
    "colors = ['lightcoral', 'lightskyblue']\n",
    "explode = (0.1, 0)  # explode 1st slice\n",
    "\n",
    "plt.title(\"Percent of comments that are insulting\")\n",
    "plt.pie(percents, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', startangle=180);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Common techniques for dealing with textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text needs special preparation before using it for predictive modeling. Usually have to convert text to numbers in some way.\n",
    "\n",
    "The most common way of working with textual data is to utilize the \"Bag of Words\" model. Each text segment gets split into words, and we count every time a word appears in each segment. Each word then gets assigned an integer ID. \n",
    "\n",
    "After transforming the text into a bag of words, there are various calculations and measurements that can be performed on the text.\n",
    "\n",
    "- **Term frequency:** how many times a term appears in the texts\n",
    "- **TF-IDF:** normalizes standard term frequency by taking into account how often words appear in general.\n",
    "- **N-grams:** The traditional bag of words model preserves no spatial information, i.e. that certain words may follow each other. The n-gram model can be used to help remedy this, by storing words in groups of n. The basic bag of words model takes n=1, and thus is a 'unigram' model. Bigram models and above can help restore spatial information.\n",
    "\n",
    "sklearn has some stuff:\n",
    "\n",
    "- Convert text to word count vectors: **CountVectorizer**\n",
    "- Convert text to word frequency vectors: **TfidfVectorizer**\n",
    "- Convert text to unique integers: **HashingVectorizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a standard (unigram) bag of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "analyze = vectorizer.build_analyzer()\n",
    "\n",
    "text = comments.iloc[9].Comment # load comment number 9\n",
    "print(text,\"\\n\")\n",
    "print(analyze(text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of bigrams: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "\n",
    "text = comments.iloc[9].Comment # load comment number 9\n",
    "print(text,\"\\n\")\n",
    "print(analyze(text)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example counting word occurences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = comments.Comment[8:10].as_matrix() # load comments 8 to 10\n",
    "corpus = np.append(corpus,\"you you you you you you you\") # add a bunch of 'yous' to make counts obvious\n",
    "\n",
    "print(\"Original documents:\\n\",corpus,\"\\n\")\n",
    "counts = vectorizer.fit_transform(corpus).toarray()\n",
    "print(\"Dictionary of words:\\n\",vectorizer.get_feature_names(),\"\\n\")\n",
    "print(\"Word frequency from dictionary, per document:\\n\",counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potentially helpful commands I just want to remember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['True_Length'].min() # finds the minimum value of specified column\n",
    "comments['True_Length'].idxmin() # finds the index of the minimum value of specified column\n",
    "comments[comments.True_Length < 2500].count().True_Length # search by some value and return the number matching\n",
    "comments.isnull().sum().Date # count how many date fields have missing values\n",
    "comments.Comment[5:10].as_matrix() # gets the comments from locs 5-10 as an array of strings\n",
    "\n",
    "print(\"end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
